# References
- ./python-attention scripts: https://medium.com/@lixue421/understanding-the-attention-mechanism-in-transformers-73ce20ead2ab

# How to navigate?
- [] [Naive attention-CPU](./python-attention-numpy): Implementation of attention mechanism using numpy
- [] [Naive attention-GPU](./naive_attn/naive_attention.cu): Implementation of naive attention mechanism using CUDA. Used as baseline for GPU parallelization.
- [] [Fused attention-GPU](./fused_attn/fused_attention.cu):
- [] [Benchmarking](./benchmark)